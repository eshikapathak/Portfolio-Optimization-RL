{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Task Discription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "We train a DRL agent for stock trading. This task is modeled as a Markov Decision Process (MDP), and the objective function is maximizing (expected) cumulative return.\n",
    "\n",
    "We specify the state-action-reward as follows:\n",
    "\n",
    "* **State s**: The state space represents an agent's perception of the market environment. Just like a human trader analyzing various information, here our agent passively observes many features and learns by interacting with the market environment (usually by replaying historical data).\n",
    "\n",
    "* **Action a**: The action space includes allowed actions that an agent can take at each state. For example, a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying. When an action operates multiple shares, a ∈{−k, ..., −1, 0, 1, ..., k}, e.g.. \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* **Reward function r(s, a, s′)**: Reward is an incentive for an agent to learn a better policy. For example, it can be the change of the portfolio value when taking a at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio values at state s′ and s, respectively\n",
    "\n",
    "\n",
    "**Market environment**: 30 consituent stocks of Dow Jones Industrial Average (DJIA) index. Accessed at the starting date of the testing period.\n",
    "\n",
    "\n",
    "The data for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Install Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. A list of Python packages \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPqeTTwoh1hn",
    "outputId": "08159edd-35c4-4dd6-8462-3e64f26d71f4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "#from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from support_files.yahoo_downloader import YahooDownloader\n",
    "from support_files.preprocessor import FeatureEngineer, data_split\n",
    "from support_files.data_processor_copy import DataProcessor\n",
    "import support_files.config as config\n",
    "import support_files.config_tickers as config_tickers\n",
    "from support_files.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from finrl.main import check_and_make_directories\n",
    "from support_files.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    ")\n",
    "from support_files.env_no_RC import StockTradingEnv as StockTradingEnv_original\n",
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "\n",
    "import os\n",
    "from mod_env_new import StockTradingEnv\n",
    "from support_files.models import DRLAgent\n",
    "from support_files.mvo_baseline import *\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RtUc_ofKmpdy"
   },
   "outputs": [],
   "source": [
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = \"snp\"\n",
    "train_gym_option = \"with_RC\"# \"original\" # or \"with_RC\"\n",
    "test_gym_option = \"with_RC\"# \"original\" # or \"with_RC\"\n",
    "\n",
    "if_using_a2c = True\n",
    "if_using_ddpg = False\n",
    "if_using_ppo = False\n",
    "if_using_td3 = False\n",
    "if_using_sac = True\n",
    "\n",
    "train_time_steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ds == \"snp\":\n",
    "    TRAIN_START_DATE = '2015-01-01'\n",
    "    TRAIN_END_DATE = '2019-10-01'\n",
    "    TRADE_START_DATE = '2021-01-01'\n",
    "    TRADE_END_DATE = '2022-10-31'\n",
    "    index = [\"^GSPC\"]\n",
    "    ticker_list = config_tickers.SP_500_TICKER[::50]\n",
    "else:\n",
    "    TRAIN_START_DATE = '2010-01-01'\n",
    "    TRAIN_END_DATE = '2021-10-01'\n",
    "    TRADE_START_DATE = '2021-10-01'\n",
    "    TRADE_END_DATE = '2023-03-01'\n",
    "    index = [\"^DJI\"]\n",
    "    ticker_list = config_tickers.DOW_30_TICKER\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
    "                     end_date = TRADE_END_DATE,\n",
    "                     ticker_list = ticker_list).fetch_data()\n",
    "\n",
    "set_index = YahooDownloader(start_date = TRADE_START_DATE,\n",
    "                     end_date = TRADE_END_DATE,\n",
    "                     ticker_list = index).fetch_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "We need to check for missing data and do feature engineering to convert the data point into a state.\n",
    "* **Adding technical indicators**. In practical trading, various information needs to be taken into account, such as historical prices, current holding shares, technical indicators, etc. Here, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* **Adding turbulence index**. Risk-aversion reflects whether an investor prefers to protect the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the turbulence index that measures extreme fluctuation of asset price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmKP-1ii3RLS",
    "outputId": "6e4b4cc7-593b-4403-eb2a-828f55ed5a89"
   },
   "outputs": [],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = INDICATORS,\n",
    "                    use_vix=True,\n",
    "                    use_turbulence=True,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kixon2tR3RLT"
   },
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Build A Market Environment in OpenAI Gym-style\n",
    "The training process involves observing stock price change, taking an action and reward's calculation. By interacting with the market environment, the agent will eventually derive a trading strategy that may maximize (expected) rewards.\n",
    "\n",
    "Our market environment, based on OpenAI Gym, simulates stock markets with historical market data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TOhcryx44bb"
   },
   "source": [
    "## Data Split\n",
    "We split the data into training set and testing set as follows:\n",
    "\n",
    "Training data period: 2009-01-01 to 2020-07-01\n",
    "\n",
    "Trading data period: 2020-07-01 to 2021-10-31\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0qaVGjLtgbI",
    "outputId": "5e364280-c418-470f-e25c-f03f56adbda7"
   },
   "outputs": [],
   "source": [
    "train = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\n",
    "trade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\n",
    "print(len(train))\n",
    "print(len(trade))\n",
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
    "\n",
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"make_plots\": True \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvo_df = processed_full.sort_values(['date','tic'],ignore_index=True)[['date','tic','close']]\n",
    "MVO_result = mvo_opt(mvo_df, stock_dimension)\n",
    "# Reset the index of the DataFrame to make the first column 'date'\n",
    "MVO_result = MVO_result.reset_index()\n",
    "# Rename the new column if it doesn't automatically name it 'date'\n",
    "MVO_result.rename(columns={'index': 'date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0qaVGjLtgbI",
    "outputId": "5e364280-c418-470f-e25c-f03f56adbda7"
   },
   "source": [
    "## Environment for Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwSvvPjutpqS",
    "outputId": "ad3318cc-a3c6-41ee-cdeb-a4eb317e33bf"
   },
   "outputs": [],
   "source": [
    "if train_gym_option == \"with RC\":\n",
    "    e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
    "else:\n",
    "    e_train_gym = StockTradingEnv_original(df = train, **env_kwargs)\n",
    "\n",
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "# print(type(env_train))\n",
    "\n",
    "if test_gym_option == \"with RC\":\n",
    "    e_trade_gym = StockTradingEnv(df = trade,turbulence_threshold = None, risk_indicator_col='vix', **env_kwargs)\n",
    "else:\n",
    "    e_trade_gym = StockTradingEnv_original(df = trade,turbulence_threshold = None, risk_indicator_col='vix', **env_kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwSvvPjutpqS",
    "outputId": "ad3318cc-a3c6-41ee-cdeb-a4eb317e33bf"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Train DRL Agents\n",
    "* The DRL algorithms are from **Stable Baselines 3**. Users are also encouraged to try **ElegantRL** and **Ray RLlib**.\n",
    "* FinRL includes fine-tuned standard DRL algorithms, such as DQN, DDPG, Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDmqOyF9h1iz"
   },
   "source": [
    "### Agent Training: 5 algorithms (A2C, DDPG, PPO, TD3, SAC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uijiWgkuh1jB"
   },
   "source": [
    "### Agent 1: A2C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUCnkn-HIbmj",
    "outputId": "6da723f6-2f9b-4d76-8872-328ef56dadfc"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "if if_using_a2c:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/a2c'\n",
    "  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_a2c.set_logger(new_logger_a2c)\n",
    "  # Save the trained model\n",
    "  model_a2c.save(RESULTS_DIR + '/a2c/trained_model_a2c.zip')\n",
    "\n",
    "try:\n",
    "    trained_a2c = agent.train_model(\n",
    "        model=model_a2c, \n",
    "        tb_log_name='a2c',\n",
    "        total_timesteps=train_time_steps #, #,\n",
    "    ) if if_using_a2c else None\n",
    "except Exception as e:\n",
    "    print(\"Failed to train due to:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRiOtrywfAo1"
   },
   "source": [
    "### Agent 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2YadjfnLwgt",
    "outputId": "883736bb-5b14-4306-816f-b7596b90275d"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")\n",
    "\n",
    "if if_using_ddpg:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ddpg'\n",
    "  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ddpg.set_logger(new_logger_ddpg)\n",
    "  # Save the trained model\n",
    "  model_ddpg.save(tmp_path + '/trained_model_ddpg.zip')\n",
    "\n",
    "try:\n",
    "    trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=train_time_steps) if if_using_ddpg else None\n",
    "except Exception as e:\n",
    "    print(\"Failed to train due to:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gDkU-j-fCmZ"
   },
   "source": [
    "### Agent 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5D5PFUhMzSV",
    "outputId": "01b7bbbb-7dce-4370-fe61-9098d4e5e978"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "\n",
    "if if_using_ppo:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ppo'\n",
    "  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ppo.set_logger(new_logger_ppo)\n",
    "  # Save the trained model\n",
    "  model_ppo.save(tmp_path + '/trained_model_ppo.zip')\n",
    "\n",
    "try:\n",
    "    trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=train_time_steps) if if_using_ppo else None\n",
    "except Exception as e:\n",
    "    print(\"Failed to train due to:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zpv4S0-fDBv"
   },
   "source": [
    "### Agent 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSAHhV4Xc-bh",
    "outputId": "b0762c2c-09b6-4351-876a-59cd08be4707"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
    "\n",
    "if if_using_td3:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/td3'\n",
    "  new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_td3.set_logger(new_logger_td3)\n",
    "  # Save the trained model\n",
    "  model_td3.save(tmp_path + '/trained_model_td3.zip')\n",
    "\n",
    "try:\n",
    "  trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=train_time_steps) if if_using_td3 else None\n",
    "except Exception as e:\n",
    "    print(\"Failed to train due to:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr49PotrfG01"
   },
   "source": [
    "### Agent 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwOhVjqRkCdM",
    "outputId": "a5ebf4e2-34ca-4bf5-8980-08d37a0659e0"
   },
   "outputs": [],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
    "\n",
    "if if_using_sac:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/sac'\n",
    "  new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_sac.set_logger(new_logger_sac)\n",
    "  # Save the trained model\n",
    "  model_sac.save(tmp_path + '/trained_model_sac.zip')\n",
    "  \n",
    "try:\n",
    "  trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=train_time_steps) if if_using_sac else None\n",
    "except Exception as e:\n",
    "    print(\"Failed to train due to:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2wZgkQXh1jE"
   },
   "source": [
    "## Test\n",
    "\n",
    "Assume that the initial capital is $1,000,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def plot_attributes(df, attributes):\n",
    "    # Ensure the date column is datetime type for better plotting\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Determine the number of subplots needed\n",
    "    n_attributes = len(attributes)\n",
    "    plt.figure(figsize=(10, 5 * n_attributes))\n",
    "    \n",
    "    # Plot each attribute in a separate subplot\n",
    "    for i, attribute in enumerate(attributes):\n",
    "        plt.subplot(n_attributes, 1, i + 1)  # Create a subplot for each attribute\n",
    "        for ticker in df['tic'].unique():\n",
    "            # Filter data for each ticker\n",
    "            stock_data = df[df['tic'] == ticker]\n",
    "            plt.plot(stock_data['date'], stock_data[attribute], label=f'{ticker}')\n",
    "\n",
    "        plt.title(f'{attribute.title()} Over Time')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel(attribute.title())\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f'{attribute}_over_time.png')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Attributes you want to plot\n",
    "attributes = ['close', 'close', 'volume', 'macd', 'rsi_30']\n",
    "\n",
    "# Call the function to plot data\n",
    "plot_attributes(trade, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lbFchno5j3xs",
    "outputId": "7eb7fa24-50a8-4506-97bf-a463e66f9102"
   },
   "outputs": [],
   "source": [
    "if if_using_a2c: \n",
    "    m = trained_a2c\n",
    "    df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
    "        model=m, \n",
    "        environment = e_trade_gym)#if if_using_a2c else None, None\n",
    "else:\n",
    "    df_account_value_a2c, df_actions_a2c = None, None\n",
    "\n",
    "if if_using_ddpg: \n",
    "    m = trained_ddpg\n",
    "    df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
    "        model=m, \n",
    "        environment = e_trade_gym)\n",
    "else: \n",
    "    df_account_value_ddpg, df_actions_ddpg = None, None\n",
    "    \n",
    "\n",
    "if if_using_ppo:\n",
    "    m = trained_ppo\n",
    "    df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
    "        model=m, \n",
    "        environment = e_trade_gym)#if if_using_ppo else None, None\n",
    "else:\n",
    "    df_account_value_ppo, df_actions_ppo = None, None\n",
    "\n",
    "if if_using_td3:\n",
    "    m = trained_td3\n",
    "    df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
    "        model=m, \n",
    "        environment = e_trade_gym) #else None, None\n",
    "else: \n",
    "    df_account_value_td3, df_actions_td3 = None, None\n",
    "\n",
    "if if_using_sac: \n",
    "    m = trained_sac\n",
    "    df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
    "        model=m, \n",
    "        environment = e_trade_gym) #if if_using_sac else None, None\n",
    "else:\n",
    "    df_account_value_sac, df_actions_sac = None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'df_a2c': df_account_value_a2c,\n",
    "    'df_sac': df_account_value_sac,\n",
    "    'df_ddpg': df_account_value_ddpg,\n",
    "    'df_ppo': df_account_value_ppo,\n",
    "    'df_td3': df_account_value_td3,\n",
    "    'df_actions_a2c': df_actions_a2c,  # assuming action DataFrames similarly named\n",
    "    'df_actions_sac': df_actions_sac,\n",
    "    'df_actions_ddpg': df_actions_ddpg,\n",
    "    'df_actions_ppo': df_actions_ppo,\n",
    "    'df_actions_td3': df_actions_td3,\n",
    "    'df_MVO': MVO_result\n",
    "}\n",
    "\n",
    "for label, df in dataframes.items():\n",
    "    if df is not None:\n",
    "        df.to_csv(f'{label+train_gym_option}.csv', index=True)\n",
    "        if label in ['df_a2c', 'df_sac', 'df_ddpg', 'df_ppo', 'df_td3']:\n",
    "            print(f\"{label} stats ---------------\")\n",
    "            stats = backtest_stats(df, value_col_name = 'account_value')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = backtest_stats(MVO_result, value_col_name = 'Mean Var')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==============Get Index Stats===========\")\n",
    "df_dji= get_baseline(\n",
    "        ticker=index[0], \n",
    "        start = TRADE_START_DATE,\n",
    "        end = TRADE_END_DATE)\n",
    "stats = backtest_stats(df_dji, value_col_name = 'close')\n",
    "\n",
    "df_dji['close'] = df_dji['close'].astype(float)\n",
    "df_dji = pd.DataFrame({\n",
    "    'date': pd.to_datetime(df_dji['date']),\n",
    "    'account_value': df_dji['close'] / df_dji['close'].iloc[0] * env_kwargs[\"initial_amount\"]  \n",
    "})\n",
    "df_dji.to_csv(\"df_dji.csv\")\n",
    "df_dji.set_index('date', inplace=True)\n",
    "df_dji.to_csv(\"df_dji+.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plot each dataset if it is not None\n",
    "if df_account_value_a2c is not None:\n",
    "    df_account_value_a2c[df_account_value_a2c.columns[0]] = pd.to_datetime(df_account_value_a2c[df_account_value_a2c.columns[0]])\n",
    "    ax1.plot(df_account_value_a2c[df_account_value_a2c.columns[0]], df_account_value_a2c[df_account_value_a2c.columns[1]], label='A2C', color='blue')\n",
    "\n",
    "if df_account_value_ddpg is not None:\n",
    "    df_account_value_ddpg[df_account_value_ddpg.columns[0]] = pd.to_datetime(df_account_value_ddpg[df_account_value_ddpg.columns[0]])\n",
    "    ax1.plot(df_account_value_ddpg[df_account_value_ddpg.columns[0]], df_account_value_ddpg[df_account_value_ddpg.columns[1]], label='DDPG', color='orange')\n",
    "\n",
    "if df_account_value_ppo is not None:\n",
    "    df_account_value_ppo[df_account_value_ppo.columns[0]] = pd.to_datetime(df_account_value_ppo[df_account_value_ppo.columns[0]])\n",
    "    ax1.plot(df_account_value_ppo[df_account_value_ppo.columns[0]], df_account_value_ppo[df_account_value_ppo.columns[1]], label='PPO', color='purple')\n",
    "\n",
    "if df_account_value_td3 is not None:\n",
    "    df_account_value_td3[df_account_value_td3.columns[0]] = pd.to_datetime(df_account_value_td3[df_account_value_td3.columns[0]])\n",
    "    ax1.plot(df_account_value_td3[df_account_value_td3.columns[0]], df_account_value_td3[df_account_value_td3.columns[1]], label='TD3', color='black')\n",
    "\n",
    "if df_account_value_sac is not None:\n",
    "    df_account_value_sac[df_account_value_sac.columns[0]] = pd.to_datetime(df_account_value_sac[df_account_value_sac.columns[0]])\n",
    "    ax1.plot(df_account_value_sac[df_account_value_sac.columns[0]], df_account_value_sac[df_account_value_sac.columns[1]], label='SAC', color='green')\n",
    "\n",
    "ax1.plot(df_dji.index, df_dji['account_value'], label=f'{index[0]}', color='red')\n",
    "ax1.plot(MVO_result['date'], MVO_result['Mean Var'], label=f'{MVO}', color='pink')\n",
    "\n",
    "# Setting labels and titles\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Account Value')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rolling_risk(df, column_name='account_value', window=3):\n",
    "    df['daily_return'] = df[column_name].pct_change()\n",
    "    df['rolling_risk'] = df['daily_return'].rolling(window).std()\n",
    "    return df\n",
    "\n",
    "# Apply the function to each DataFrame if they exist\n",
    "if df_account_value_a2c is not None:\n",
    "    df_account_value_a2c = calculate_rolling_risk(df_account_value_a2c)\n",
    "if df_account_value_sac is not None:\n",
    "    df_account_value_sac = calculate_rolling_risk(df_account_value_sac)\n",
    "if df_account_value_ddpg is not None:\n",
    "    df_account_value_ddpg = calculate_rolling_risk(df_account_value_ddpg)\n",
    "if df_account_value_ppo is not None:\n",
    "    df_account_value_ppo = calculate_rolling_risk(df_account_value_ppo)\n",
    "if df_account_value_td3 is not None:\n",
    "    df_account_value_td3 = calculate_rolling_risk(df_account_value_td3)\n",
    "if df_dji is not None:\n",
    "    df_dji = calculate_rolling_risk(df_dji, 'account_value')  \n",
    "if MVO_result is not None:\n",
    "    MVO_result = calculate_rolling_risk(MVO_result, 'Mean Var') \n",
    "\n",
    "set_index['date'] = pd.to_datetime(set_index['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Define the figure and primary axis\n",
    "fig, ax1 = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "# Plot rolling risks for each model on the primary axis\n",
    "models = {\n",
    "    'A2C': (df_account_value_a2c, 'blue'),\n",
    "    'SAC': (df_account_value_sac, 'green'),\n",
    "    'DDPG': (df_account_value_ddpg, 'orange'),\n",
    "    'PPO': (df_account_value_ppo, 'purple'),\n",
    "    'TD3': (df_account_value_td3, 'black'),\n",
    "    'DJI': (df_dji, 'red'),\n",
    "    'MVO': (MVO_result, 'pink')\n",
    "}\n",
    "for model, (df, color) in models.items():\n",
    "    if df is not None and 'rolling_risk' in df.columns and 'date' in df.columns:\n",
    "        ax1.plot(df['date'], df['rolling_risk'], label=f'{model} Risk', color=color)\n",
    "\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Rolling Standard Deviation of Daily Returns')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Set up the secondary axis\n",
    "ax2 = ax1.twinx()\n",
    "if set_index is not None:\n",
    "    ax2.plot(set_index['date'], set_index['close'], '--', label='S&P 500' if ds==\"snp\" else 'DJI', color='magenta')\n",
    "    ax2.set_ylabel(f'{index[0]} Close Price')\n",
    "    ax2.legend(loc='upper right')\n",
    "\n",
    "# Title for the figure\n",
    "plt.title(f'Comparison of Rolling Risks across Models with {index[0]} Index')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "HMNR5nHjh1iz",
    "uijiWgkuh1jB",
    "MRiOtrywfAo1",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "54cefccbf0f07c9750f12aa115c023dfa5ed4acecf9e7ad3bc9391869be60d0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
